{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "DM-VTON"
      ],
      "metadata": {
        "id": "XCXmNZTKkdI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ArefMYTB/DM-VTON.git\n",
        "%cd DM-VTON"
      ],
      "metadata": {
        "id": "Y0yaLZ-wjzlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3bc9ae7-dab7-4d55-cdce-86a1f65a245d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DM-VTON'...\n",
            "remote: Enumerating objects: 1496, done.\u001b[K\n",
            "remote: Counting objects: 100% (563/563), done.\u001b[K\n",
            "remote: Compressing objects: 100% (389/389), done.\u001b[K\n",
            "remote: Total 1496 (delta 188), reused 345 (delta 163), pack-reused 933\u001b[K\n",
            "Receiving objects: 100% (1496/1496), 3.94 MiB | 5.88 MiB/s, done.\n",
            "Resolving deltas: 100% (585/585), done.\n",
            "/content/DM-VTON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "U8jL8WYlj7Zx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14e3da30-5d56-478e-a430-2c81a14079e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX>=2.6 (from -r requirements.txt (line 7))\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.66.4)\n",
            "Collecting scipy==1.11.1 (from -r requirements.txt (line 9))\n",
            "  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting thop==0.1.1.post2209072238 (from -r requirements.txt (line 10))\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: opencv-python>=4.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (4.8.0.76)\n",
            "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from scipy==1.11.1->-r requirements.txt (line 9)) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (2.3.0+cu121)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->-r requirements.txt (line 7)) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX>=2.6->-r requirements.txt (line 7)) (3.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->thop==0.1.1.post2209072238->-r requirements.txt (line 10)) (1.3.0)\n",
            "Installing collected packages: tensorboardX, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.11.4\n",
            "    Uninstalling scipy-1.11.4:\n",
            "      Successfully uninstalled scipy-1.11.4\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 scipy-1.11.1 tensorboardX-2.6.2.2 thop-0.1.1.post2209072238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download VITON-Clean dataset\n",
        "!mkdir ../dataset\n",
        "!gdown 1-5FtBJtel-ujgKR_TqJEcN2KrhyjBcyp -O ../dataset/VITON-Clean.zip\n",
        "!unzip ../dataset/VITON-Clean.zip -d ../dataset\n",
        "!rm ../dataset/VITON-Clean.zip"
      ],
      "metadata": {
        "id": "ffSZQkjyj-gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip ../dataset/test.zip -d ../dataset\n",
        "!rm ../dataset/test.zip"
      ],
      "metadata": {
        "id": "Ol7YhKZOnaYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download checkpoints\n",
        "!mkdir checkpoints\n",
        "!gdown 16H16AhGJrqndDrAaHWZvTFzGSsaDecpS -O checkpoints/dmvton_pf_warp.pt\n",
        "!gdown 1i-Ple5L9__LV_Fbx1cZyxiOC-CRFxi0C -O checkpoints/dmvton_pf_gen.pt"
      ],
      "metadata": {
        "id": "QdeQyrAakByH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c4639df-4d7e-45c7-b6d8-836de5e643e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=16H16AhGJrqndDrAaHWZvTFzGSsaDecpS\n",
            "From (redirected): https://drive.google.com/uc?id=16H16AhGJrqndDrAaHWZvTFzGSsaDecpS&confirm=t&uuid=11492508-8097-4b24-87b5-66edd232b2ae\n",
            "To: /content/DM-VTON/checkpoints/dmvton_pf_warp.pt\n",
            "100% 86.5M/86.5M [00:02<00:00, 30.0MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1i-Ple5L9__LV_Fbx1cZyxiOC-CRFxi0C\n",
            "From (redirected): https://drive.google.com/uc?id=1i-Ple5L9__LV_Fbx1cZyxiOC-CRFxi0C&confirm=t&uuid=2d9df1db-0a94-4dab-bc7a-1722d1baa3d8\n",
            "To: /content/DM-VTON/checkpoints/dmvton_pf_gen.pt\n",
            "100% 26.4M/26.4M [00:01<00:00, 22.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "shutil.rmtree(\"/content/DM-VTON/runs\")"
      ],
      "metadata": {
        "id": "3gOKmGaha8CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set batch_size = 1 to save each image separately\n",
        "!python test.py --project runs/test --name DM-VTON_demo \\\n",
        "--device 0 --align_corners --batch_size 1 --workers 16 \\\n",
        "--dataroot ../dataset/test \\\n",
        "--pf_warp_checkpoint checkpoints/dmvton_pf_warp.pt \\\n",
        "--pf_gen_checkpoint checkpoints/dmvton_pf_gen.pt"
      ],
      "metadata": {
        "id": "9T8_EeookGW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "from google.colab import files\n",
        "\n",
        "# Path to the folder you want to download\n",
        "folder_path = '/content/DM-VTON/images'\n",
        "\n",
        "# Zip the folder\n",
        "shutil.make_archive('/content/sample_folder', 'zip', folder_path)\n",
        "\n",
        "# Download the zip file\n",
        "files.download('/content/sample_folder.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "T3Dhui80m0Bg",
        "outputId": "f5485bf7-4489-4eef-b7d1-ce02b4c6a495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6c2c64c5-b698-4339-9f73-ea0e56ef66e6\", \"sample_folder.zip\", 2159729)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bug in Colab"
      ],
      "metadata": {
        "id": "V6lUhE8JiA7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "print(locale.getpreferredencoding())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5osvX1NEc_S3",
        "outputId": "91d660eb-b9df-4c9d-fcf4-80bfc978dca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ANSI_X3.4-1968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "def getpreferredencoding(do_setlocale = True):\n",
        "    return \"UTF-8\"\n",
        "locale.getpreferredencoding = getpreferredencoding"
      ],
      "metadata": {
        "id": "pxPkVt3Fc_zv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run here"
      ],
      "metadata": {
        "id": "GYwC13NOAAYK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "G6Fmwdg_JXJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cupy\n",
        "import torch\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image, ImageDraw\n",
        "\n",
        "from pipelines import DMVTONPipeline\n",
        "from utils.general import Profile, print_log, warm_up\n",
        "from utils.torch_utils import select_device"
      ],
      "metadata": {
        "id": "pxZV00d6D9XH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RUN VTON"
      ],
      "metadata": {
        "id": "pfLNBUkSJS8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = select_device(0, batch_size=1)\n",
        "\n",
        "# Inference Pipeline\n",
        "pipeline = DMVTONPipeline(\n",
        "    checkpoints={\n",
        "        'warp': \"checkpoints/dmvton_pf_warp.pt\",\n",
        "        'gen': \"checkpoints/dmvton_pf_gen.pt\",\n",
        "    },\n",
        ").to(device)\n",
        "pipeline.eval()"
      ],
      "metadata": {
        "id": "wTnmwhpQNjcH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_test_pf(\n",
        "    pipeline, real_image, clothes, edge, device\n",
        "):\n",
        "\n",
        "  # Warm-up gpu\n",
        "    dummy_input = {\n",
        "        'person': torch.randn(1, 3, 256, 192).to(device),\n",
        "        'clothes': torch.randn(1, 3, 256, 192).to(device),\n",
        "        'clothes_edge': torch.randn(1, 1, 256, 192).to(device),\n",
        "    }\n",
        "    with cupy.cuda.Device(int(device.split(':')[-1])):\n",
        "        warm_up(pipeline, **dummy_input)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        seen, dt = 0, Profile(device=device)\n",
        "        # Prepare data\n",
        "        real_image = real_image.to(device)\n",
        "        clothes = clothes.to(device)\n",
        "        edge = edge.to(device)\n",
        "\n",
        "        with cupy.cuda.Device(int(device.split(':')[-1])):\n",
        "            with dt:\n",
        "                p_tryon, warped_cloth = pipeline(real_image, clothes, edge, phase=\"test\")\n",
        "\n",
        "        return p_tryon, warped_cloth\n"
      ],
      "metadata": {
        "id": "ARwQ-g45A0HE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data loader functions"
      ],
      "metadata": {
        "id": "Hd6AJxABJAbz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one(person):\n",
        "  phase = \"test\"\n",
        "\n",
        "  transform_image = get_transform(train=(phase == 'train'))\n",
        "  transform_parse = get_transform(\n",
        "      train=(phase == 'train'), method=Image.NEAREST, normalize=False\n",
        "  )\n",
        "\n",
        "  if type(person) == str:\n",
        "    img = Image.open(person).convert('RGB')\n",
        "  else:\n",
        "    img = Image.fromarray(person).convert('RGB')\n",
        "  img_tensor = transform_image(img)\n",
        "\n",
        "  return img_tensor\n",
        "\n",
        "\n",
        "def __getitem__(person, target, edge):\n",
        "\n",
        "\n",
        "  phase = \"test\"\n",
        "\n",
        "  transform_image = get_transform(train=(phase == 'train'))\n",
        "  transform_parse = get_transform(\n",
        "      train=(phase == 'train'), method=Image.NEAREST, normalize=False\n",
        "  )\n",
        "\n",
        "  if type(person) == str:\n",
        "    img = Image.open(person).convert('RGB')\n",
        "  else:\n",
        "    imge = person.convert('RGB')\n",
        "  img_tensor = transform_image(img)\n",
        "\n",
        "  if type(target) == str:\n",
        "    cloth = Image.open(target).convert('RGB')\n",
        "  else:\n",
        "    cloth = target.convert('RGB')\n",
        "  cloth_tensor = transform_image(cloth)\n",
        "\n",
        "  if type(edge) == str:\n",
        "    cloth_edge = Image.open(edge).convert('L')\n",
        "  else:\n",
        "    cloth_edge = edge.convert('L')\n",
        "  cloth_edge_tensor = transform_parse(cloth_edge)\n",
        "\n",
        "\n",
        "  return img_tensor, cloth_tensor, cloth_edge_tensor\n",
        "\n",
        "\n",
        "\n",
        "def get_transform(train, method=Image.BICUBIC, normalize=True):\n",
        "    transform_list = []\n",
        "\n",
        "    base = float(2**4)\n",
        "    transform_list.append(transforms.Lambda(lambda img: __make_power_2(img, base, method)))\n",
        "\n",
        "    if train:\n",
        "        transform_list.append(transforms.Lambda(lambda img: __flip(img, 0)))\n",
        "\n",
        "    transform_list += [transforms.ToTensor()]\n",
        "\n",
        "    if normalize:\n",
        "        transform_list += [transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        "    return transforms.Compose(transform_list)\n",
        "\n",
        "\n",
        "def normalize():\n",
        "    return transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "\n",
        "\n",
        "def __make_power_2(img, base, method=Image.BICUBIC):\n",
        "    try:\n",
        "        ow, oh = img.size  # PIL\n",
        "    except Exception:\n",
        "        oh, ow = img.shape  # numpy\n",
        "    h = int(round(oh / base) * base)\n",
        "    w = int(round(ow / base) * base)\n",
        "    if (h == oh) and (w == ow):\n",
        "        return img\n",
        "    return img.resize((w, h), method)\n",
        "\n",
        "\n",
        "def __flip(img, flip):\n",
        "    if flip:\n",
        "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    return img"
      ],
      "metadata": {
        "id": "6EJtnQ04I90_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on image"
      ],
      "metadata": {
        "id": "DlM-9w9qJHFq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = \"/content/dataset/test/test_img/000057_0.jpg\"\n",
        "target_path = \"/content/dataset/test/test_color/000523_1.jpg\"\n",
        "edge_path = \"/content/dataset/test/test_edge/000523_1.jpg\"\n",
        "\n",
        "image_tensor, target_tensor, edge_tensor = __getitem__(image_path, target_path, edge_path)\n",
        "\n",
        "image_tensor = image_tensor.unsqueeze(0)\n",
        "target_tensor = target_tensor.unsqueeze(0)\n",
        "edge_tensor = edge_tensor.unsqueeze(0)\n",
        "\n",
        "p_tryon, warped_cloth = run_test_pf(\n",
        "        pipeline=pipeline,\n",
        "        real_image=image_tensor,\n",
        "        clothes=target_tensor,\n",
        "        edge=edge_tensor,\n",
        "        device=device,\n",
        "    )"
      ],
      "metadata": {
        "id": "0fPF_9dJAC25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cebbb423-3fd9-49ba-886d-644386c3961c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3809: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n",
            "/usr/local/lib/python3.10/dist-packages/cupy/cuda/compiler.py:464: UserWarning: cupy.cuda.compile_with_cache has been deprecated in CuPy v10, and will be removed in the future. Use cupy.RawModule or cupy.RawKernel instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torch/functional.py:512: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3587.)\n",
            "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision as tv"
      ],
      "metadata": {
        "id": "VKWhrMLVhO1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tv.utils.save_image(\n",
        "                    p_tryon[0],\n",
        "                    \"test.jpg\",\n",
        "                    nrow=int(1),\n",
        "                    normalize=True,\n",
        "                    value_range=(-1, 1),\n",
        "                )"
      ],
      "metadata": {
        "id": "Kk7F4LpBf5wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test on Video"
      ],
      "metadata": {
        "id": "86mcYUxVjxMK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QpHobCRBdvRl"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "# from google.colab import files\n",
        "\n",
        "# # Upload the video file\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Load the video\n",
        "# video_path = next(iter(uploaded))\n",
        "video_path = \"girl.mp4\"\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "output_size = (192, 256)\n",
        "\n",
        "# Get video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
        "out = cv2.VideoWriter('flipped_video.avi', fourcc, fps, (width, height))\n",
        "\n",
        "images = []\n",
        "# Read and flip each frame\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "    # Flip the frame horizontally\n",
        "    # flipped_frame = cv2.flip(frame, 1)\n",
        "\n",
        "    resized_frame = cv2.resize(frame, output_size)\n",
        "\n",
        "    # try on\n",
        "    img_tensor = get_one(resized_frame)\n",
        "    # print(resized_frame.shape)\n",
        "    # print(img_tensor.shape)\n",
        "    img_tensor = img_tensor.unsqueeze(0)\n",
        "    # print(img_tensor.shape)\n",
        "\n",
        "    p_tryon, warped_cloth = run_test_pf(\n",
        "        pipeline=pipeline,\n",
        "        real_image=img_tensor,\n",
        "        clothes=target_tensor,\n",
        "        edge=edge_tensor,\n",
        "        device=device,\n",
        "    )\n",
        "\n",
        "    images.append(p_tryon)\n",
        "\n",
        "\n",
        "    # Write the flipped frame to the output video\n",
        "    # out.write(resized_frame)\n",
        "\n",
        "# Release everything if job is finished\n",
        "cap.release()\n",
        "# out.release()\n",
        "\n",
        "print(\"Video flipping completed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pcw5Zht01I7Y",
        "outputId": "cf4cb928-2065-4a28-fab6-8dffbd569747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for j in range(len(images)):\n",
        "\n",
        "                tv.utils.save_image(\n",
        "                    images[j],\n",
        "                    f\"images/t{j}.jpg\",\n",
        "                    nrow=int(1),\n",
        "                    normalize=True,\n",
        "                    value_range=(-1, 1),\n",
        "                )"
      ],
      "metadata": {
        "id": "gYwvJkkY0omI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}